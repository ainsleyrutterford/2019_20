## Information Processing and the Brain 2019/2020

Here you can find the relevant content for Information Processing and the Brain 2019/2020. This unit covers several aspects of information processing in the brain, such as sensory processing, probabilistic codes, deep learning, recurrent neural networks, credit assignment, reinforcement learning and model-based inference.

It is jointly taught by Conor Houghton and Rui Ponte Costa at the
Department of Computer Science [School of Computer Science, Electrical
and Electronic Engineering, and Engineering Mathematics], Faculty of
Engineering, University of Bristol.

You should go to the io page for links to the reddit and to the 2018-19 version of this unit:
[comsm0034.github.io](http://comsm0034.github.io "unit homepage") 

### Recommended reading:

This field is highlight interdisciplinary, as such there is no single textbook that covers all our lectures. However, below we highlight **in bold** the most relevant ones for this unit.
Theoretical neuroscience:

1. **Theoretical Neuroscience by P Dayan and L F Abbott (MIT Press 2001)**, see also errata.
2. Neuronal Dynamics by Wulfram Gerstner, Werner M. Kistler, Richard Naud and Liam Paninski. Full version online.
3. Introduction To The Theory Of Neural Computation, Volume I by John Hertz. (Classical and accessible book on neural computation)
4. Bayesian Brain: Probabilistic Approaches to Neural Coding
5. **Elements of Information Theory by TM Cover and JA Thomas (Wiley)**, worth owning, but there is an online pdf from [www.cs-114.org](http://www.cs-114.org/wp-content/uploads/2015/01/Elements_of_Information_Theory_Elements.pdf "Cover and Thomas pdf")

Machine/statistical Learning:

1. General ML book: Information Theory, Inference and Learning Algorithms by David MacKay. Full version available online
2. **Deep Learning (including Recurrent neural nets): Deep Learning by Ian Goodfellow, Yoshua Bengio and Aaron Courville**
3. Unsupervised learning: Natural Image Statistics by Aapo Hyvarinen, Jarmo Hurri, and Patrik O. Hoyer. Full version available online.
4. Reinforcement learning: Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto. Full version available online.

**Super useful math/stat cheat-sheet by Iain Murray**:
[homepages.inf.ed.ac.uk/imurray2/pub/cribsheet.pdf](https://homepages.inf.ed.ac.uk/imurray2/pub/cribsheet.pdf)


### Draft schedule

#### Conor:

* Lecture 1-3: Information theory
* Lecture 4-5: Statistical theory
* Lecture 6-9: Probabilistic brain

#### Guest lecturer:

* Lecture 10: Laurence?

#### Rui: Neural circuits and learning

* Lecture 10: Different forms of learning (1,4)
* Lecture 11-12: Visual System: conv nets and backprop (5,6)
* Lecture 13-14: Supervised learning (1,4)
* Lecture 15: Sparse coding and autoencoders (5,6)
* Lecture 16: Reinforcement Learning: TD-learning, Q-Learning, Deep RL (1,7)
* Lecture 17-18: Auditory cortex, Recurrent neural networks, gated RNNs (1,4)

#### Cian:

* Lecture 19-20: Neural Data Analysis

#### Revision week:

* Lecture 21: Conor's revision
* Lecture 22: Rui/Cian revision
